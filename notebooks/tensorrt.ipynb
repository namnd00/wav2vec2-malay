{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorrt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQvB5l2huTmd",
        "outputId": "15da82d5-5665-4d45-e60b-10c4e91e106c"
      },
      "source": [
        "%cd /content/sample_data"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "furT8YP-r0cc"
      },
      "source": [
        "#!pip install trtorch "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax3hV6extUV5"
      },
      "source": [
        "#!git clone -b master https://github.com/nvidia/TensorRT TensorRT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-D2axWQ-tWMA"
      },
      "source": [
        "#%cd TensorRT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_3b7FKH2IP4"
      },
      "source": [
        "#!git submodule update --init --recursive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kogylNQz2TL_"
      },
      "source": [
        "#!./docker/build.sh --file docker/ubuntu-18.04.Dockerfile --tag tensorrt-ubuntu18.04-cuda11.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srByNA2uypEf",
        "outputId": "7eb2a721-8614-4c32-a2b4-41bb56ec8203"
      },
      "source": [
        "!gdown --id 1q-lnbnWv9pdM3xTavvAvhP57oW5z88yN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1q-lnbnWv9pdM3xTavvAvhP57oW5z88yN\n",
            "To: /content/sample_data/checkpoint-162225.zip\n",
            "100% 1.17G/1.17G [00:07<00:00, 154MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2RalOQkzBhz",
        "outputId": "0aa6cfe6-d513-4104-ccf3-2728727b862f"
      },
      "source": [
        "!unzip /content/sample_data/checkpoint-162225.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/sample_data/checkpoint-162225.zip\n",
            "replace checkpoint-162225/preprocessor_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5i8cpknzLbM",
        "outputId": "771bf966-f834-4135-95a3-5cda5714fbc9"
      },
      "source": [
        "#!pip install onnx onnxruntime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.10.2)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "7sc6Q5SHImqN",
        "outputId": "56bf2e6e-cde9-4196-bb59-3974f374ceaf"
      },
      "source": [
        "!pip install onnxruntime-gpu"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnxruntime-gpu\n",
            "  Downloading onnxruntime_gpu-1.9.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (95.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 95.6 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (1.12)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->onnxruntime-gpu) (1.15.0)\n",
            "Installing collected packages: onnxruntime-gpu\n",
            "Successfully installed onnxruntime-gpu-1.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "onnxruntime"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L525sn3U1jbO",
        "outputId": "c186178e-dabc-48bb-92f4-5c199db73508"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuVaM9W62_3s"
      },
      "source": [
        "import soundfile as sf\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0I0ukfpCXQ2"
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6tlHSQhzx4y"
      },
      "source": [
        "import io\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.onnx\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SbN-0Px01hf4",
        "outputId": "477bbccc-f0a8-48b1-b1ad-efc8faa5607f"
      },
      "source": [
        "model = Wav2Vec2ForCTC.from_pretrained(\"/content/sample_data/checkpoint-162225\").to(\"cuda\")\n",
        "processor = Wav2Vec2Processor.from_pretrained(\"/content/sample_data/checkpoint-162225\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0zB8r7x3EW6"
      },
      "source": [
        "audio, sr = sf.read(\"/content/sample_data/fp6ABAjcXPI.0008.wav\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg0uAtCb3McB",
        "outputId": "f41f5052-211f-47d9-9970-182436abf822"
      },
      "source": [
        "np.shape(audio)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31664,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF6Zew4Hz0dy"
      },
      "source": [
        "inputs = processor(audio, sampling_rate=16_000, return_tensors=\"pt\", padding=True).to(\"cuda\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2j7k66v3Vww",
        "outputId": "13b2fdfc-3e5d-4388-a072-2be4c7bff339"
      },
      "source": [
        "np.shape(inputs.input_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 31664])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_dZYqjQ5GAP"
      },
      "source": [
        "batch_size = 1\n",
        "size_audio = 16000"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAc7hZ953gvx"
      },
      "source": [
        "x = torch.randn(batch_size, size_audio , requires_grad=True).to(\"cuda\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mV0Bk_b-E9c",
        "outputId": "0aa50783-0419-40b9-946d-e38fcd43ab11"
      },
      "source": [
        "type(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2ahwO6f7eNj"
      },
      "source": [
        "torch_out = model(x)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KCdcGuk-HyX",
        "outputId": "7dc5a415-e362-4bd0-8282-76e11eae939f"
      },
      "source": [
        "type(torch_out.logits)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfPyryON5K1d",
        "outputId": "264dbfc4-1db6-4bf6-8852-d5a9be9e9236"
      },
      "source": [
        "torch.onnx.export(model,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"super_resolution.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=10,          # the ONNX version to export the model to\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output'], # the model's output names\n",
        "                  dynamic_axes={'input' : {0 : 'batch_size', 1: \"size_audio\"},    # variable length axes\n",
        "                                'output' : {0 : 'batch_size', 1: \"size_audio\"}})"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:538: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/models/wav2vec2/modeling_wav2vec2.py:575: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld_fRSna6NyU"
      },
      "source": [
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(\"super_resolution.onnx\")\n",
        "onnx.checker.check_model(onnx_model)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1ZIpj9s62mx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57293f4-85da-41b2-d4a4-6a860590d09e"
      },
      "source": [
        "import onnxruntime\n",
        "\n",
        "ort_session = onnxruntime.InferenceSession(\"super_resolution.onnx\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py:353: UserWarning: Deprecation warning. This ORT build has ['CUDAExecutionProvider', 'CPUExecutionProvider'] enabled. The next release (ORT 1.10) will require explicitly setting the providers parameter (as opposed to the current behavior of providers getting set/registered by default based on the build flags) when instantiating InferenceSession.For example, onnxruntime.InferenceSession(..., providers=[\"CUDAExecutionProvider\"], ...)\n",
            "  \"based on the build flags) when instantiating InferenceSession.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dI_rCY78JpGa",
        "outputId": "afbe5fbf-3147-4915-ef0c-3c887eace636"
      },
      "source": [
        "onnxruntime.get_device()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'GPU'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8yGoTEFr63kn",
        "outputId": "203e686c-4278-4fd3-d575-5b1b943d0588"
      },
      "source": [
        "def to_numpy(tensor):\n",
        "    start = time()\n",
        "    result = tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
        "    end = time()\n",
        "    print(\"time to numpy %f\" %(end-start))\n",
        "    return result\n",
        "# compute ONNX Runtime output prediction\n",
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(x)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "\n",
        "# compare ONNX Runtime and PyTorch results\n",
        "np.testing.assert_allclose(to_numpy(torch_out.logits), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
        "\n",
        "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time to numpy 0.001126\n",
            "time to numpy 0.000237\n",
            "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yva9kswh-twu",
        "outputId": "085f8fdb-706e-4deb-c90f-965a9f798cff"
      },
      "source": [
        "ort_outs"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[[ -1.5236202,  -5.859751 , -10.887591 , ...,  -2.9987051,\n",
              "          -23.808561 ,  11.289816 ],\n",
              "         [ -1.877117 ,  -6.2698994, -12.296979 , ...,  -3.6036615,\n",
              "          -25.525177 ,  12.7112465],\n",
              "         [ -1.8982913,  -6.290418 , -12.582239 , ...,  -3.677633 ,\n",
              "          -25.96843  ,  13.105109 ],\n",
              "         ...,\n",
              "         [ -2.102715 ,  -6.1728196, -12.379694 , ...,  -4.001382 ,\n",
              "          -26.481075 ,  12.929312 ],\n",
              "         [ -1.8755506,  -6.018666 , -12.206705 , ...,  -4.291876 ,\n",
              "          -25.908623 ,  12.990101 ],\n",
              "         [ -1.6166798,  -5.806743 , -11.693392 , ...,  -4.397772 ,\n",
              "          -25.472271 ,  12.503278 ]]], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFbscEbB-3PM",
        "outputId": "31c5efc0-2df2-4b55-dd4d-ba2bc6d159d8"
      },
      "source": [
        "torch_out"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CausalLMOutput([('logits',\n",
              "                 tensor([[[ -1.5236,  -5.8598, -10.8876,  ...,  -2.9987, -23.8085,  11.2898],\n",
              "                          [ -1.8771,  -6.2699, -12.2970,  ...,  -3.6037, -25.5252,  12.7113],\n",
              "                          [ -1.8983,  -6.2904, -12.5822,  ...,  -3.6776, -25.9684,  13.1051],\n",
              "                          ...,\n",
              "                          [ -2.1027,  -6.1728, -12.3797,  ...,  -4.0014, -26.4810,  12.9293],\n",
              "                          [ -1.8756,  -6.0187, -12.2067,  ...,  -4.2919, -25.9086,  12.9901],\n",
              "                          [ -1.6167,  -5.8067, -11.6934,  ...,  -4.3978, -25.4723,  12.5033]]],\n",
              "                        device='cuda:0', grad_fn=<AddBackward0>))])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mf7KG_GL_VQe"
      },
      "source": [
        "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(inputs.input_values)}\n",
        "ort_outs = ort_session.run(None, ort_inputs)\n",
        "img_out_y = ort_outs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92AAaDQy_nAt",
        "outputId": "c13c43ec-1960-40f7-add3-6d8c3ca03f56"
      },
      "source": [
        "img_out_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  3.0382507,   2.5965843,  -5.1624994, ...,   2.8944583,\n",
              "         -16.373123 ,   6.0509295],\n",
              "        [ -2.713927 ,  -3.764171 ,  -7.221685 , ...,  -2.4261508,\n",
              "         -16.75057  ,   7.7543693],\n",
              "        [  0.3424537,  -2.1360927,  -7.2895823, ...,   2.083418 ,\n",
              "         -15.00036  ,   7.149744 ],\n",
              "        ...,\n",
              "        [ -1.8987188,  -5.024401 , -11.948967 , ...,  -3.897209 ,\n",
              "         -24.465649 ,  14.01545  ],\n",
              "        [ -1.9270054,  -4.8025517, -11.571903 , ...,  -3.082398 ,\n",
              "         -23.997757 ,  13.85802  ],\n",
              "        [ -2.5925958,  -5.4269423, -11.90817  , ...,  -3.3396032,\n",
              "         -24.5448   ,  13.983185 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZn9SnHW_ycz",
        "outputId": "d57abe18-9a0e-4410-b15a-64f4b5ac90bf"
      },
      "source": [
        "predicted_ids = np.argmax(img_out_y, axis=-1)\n",
        "transcription = processor.decode(predicted_ids[0])\n",
        "print(transcription)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maklumkan 5 minit setiap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GzkvYbq_ozp",
        "outputId": "f204c048-e17d-43db-d680-34f8a83fb7ac"
      },
      "source": [
        "with torch.no_grad():\n",
        "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrtariyB_uGa",
        "outputId": "c2f34951-352d-41a2-98c9-1407faea85e5"
      },
      "source": [
        "logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  3.0382,   2.5966,  -5.1625,  ...,   2.8945, -16.3731,   6.0509],\n",
              "         [ -2.7139,  -3.7642,  -7.2217,  ...,  -2.4261, -16.7506,   7.7544],\n",
              "         [  0.3425,  -2.1361,  -7.2896,  ...,   2.0834, -15.0004,   7.1497],\n",
              "         ...,\n",
              "         [ -1.8987,  -5.0244, -11.9490,  ...,  -3.8972, -24.4656,  14.0154],\n",
              "         [ -1.9270,  -4.8026, -11.5719,  ...,  -3.0824, -23.9978,  13.8580],\n",
              "         [ -2.5926,  -5.4270, -11.9082,  ...,  -3.3396, -24.5448,  13.9832]]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se1A57uN_uo1",
        "outputId": "dba968be-66c6-49ab-f8fd-f8231769eb64"
      },
      "source": [
        "predicted_ids = torch.argmax(logits, dim=-1)\n",
        "transcription = processor.decode(predicted_ids[0])\n",
        "print(transcription)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maklumkan 5 minit setiap\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqZil1adDsX6"
      },
      "source": [
        "audio, sr = sf.read(\"/content/sample_data/fp6ABAjcXPI.0019.wav\")\n",
        "inputs = processor(audio, sampling_rate=16_000, return_tensors=\"pt\", padding=True).to(\"cuda\")"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te_NTY-UB8_h"
      },
      "source": [
        "def infer_with_onnx(inputs):\n",
        "  start_time = time()\n",
        "  ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(inputs.input_values)}\n",
        "  ort_time = time()\n",
        "  print(f\"ort_time: {ort_time - start_time}\")\n",
        "  ort_outs = ort_session.run(None, ort_inputs)\n",
        "  logits = ort_outs[0]\n",
        "  predict_time = time()\n",
        "  predicted_ids = np.argmax(logits, axis=-1)\n",
        "  transcription = processor.decode(predicted_ids[0])\n",
        "  end_time = time()\n",
        "  print(f\"{transcription} , pred_time: {predict_time - start_time}\")\n",
        "  return transcription"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNOSyDinCu1d",
        "outputId": "e8fc216e-a4af-4b6f-b32d-d14340f45f99"
      },
      "source": [
        "a = infer_with_onnx(inputs)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time to numpy 0.000257\n",
            "ort_time: 0.0004115104675292969\n",
            "dengan penupekerti bersama menya , pred_time: 0.15183639526367188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meBM2jbpC8c8"
      },
      "source": [
        "def infer_with_normal(input):\n",
        "  start_time = time()\n",
        "  with torch.no_grad():\n",
        "    logits = model(inputs.input_values, attention_mask=inputs.attention_mask).logits\n",
        "  predict_time = time()\n",
        "  predicted_ids = torch.argmax(logits, axis=-1)\n",
        "  transcription = processor.decode(predicted_ids[0])\n",
        "  end_time = time()\n",
        "  print(f\"{transcription} , pred_time: {predict_time - start_time}\")\n",
        "  return transcription"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHlQCjWaDTWz",
        "outputId": "76d6f54a-a11b-4bfa-b32b-10c5b14ca23a"
      },
      "source": [
        "b = infer_with_normal(inputs)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dengan penupekerti bersama menya , pred_time: 0.060021162033081055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsYvkz52GrN9"
      },
      "source": [
        "c = to_numpy(inputs.input_values.to(\"cuda\"))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ijz05xUGuFY",
        "outputId": "74c15bfe-afe9-4b6a-e366-79070602a122"
      },
      "source": [
        "np.shape(inputs.input_values[0])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([34576])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O53V5NZ9HGXk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}